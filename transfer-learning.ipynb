{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6384688-2e2b-41ce-b045-617385289a73",
   "metadata": {},
   "source": [
    "There are two primary types of transfer learning:\n",
    "\n",
    "Transfer learning via **feature extraction**: We remove the FC layer head from the pre-trained network and replace it with a softmax classifier. This method is super simple as it allows us to treat the pre-trained CNN as a feature extractor and then pass those features through a Logistic Regression classifier.\n",
    "\n",
    "Transfer learning via **fine-tuning**: When applying fine-tuning, we again remove the FC layer head from the pre-trained network, but this time we construct a brand new, freshly initialized FC layer head and place it on top of the original body of the network. The weights in the body of the CNN are frozen, and then we train the new layer head (typically with a very small learning rate). We may then choose to unfreeze the body of the network and train the entire network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7714c1b-b9cb-4db5-a6d0-8306c6ead616",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d86d801-6858-468c-b14e-1eb4eaddc20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e764d579-2c97-4421-aa29-e1059d742afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n",
      "bn1\n",
      "relu\n",
      "maxpool\n",
      "layer1\n",
      "layer2\n",
      "layer3\n",
      "layer4\n",
      "avgpool\n",
      "fc\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "for key, module in model._modules.items():\n",
    "    print(key)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd39348b-effd-4f0f-89d4-39c61f3e6111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 512, 512]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 512, 512]             128\n",
      "              ReLU-3         [-1, 64, 512, 512]               0\n",
      "         MaxPool2d-4         [-1, 64, 256, 256]               0\n",
      "            Conv2d-5         [-1, 64, 256, 256]           4,096\n",
      "       BatchNorm2d-6         [-1, 64, 256, 256]             128\n",
      "              ReLU-7         [-1, 64, 256, 256]               0\n",
      "            Conv2d-8         [-1, 64, 256, 256]          36,864\n",
      "       BatchNorm2d-9         [-1, 64, 256, 256]             128\n",
      "             ReLU-10         [-1, 64, 256, 256]               0\n",
      "           Conv2d-11        [-1, 256, 256, 256]          16,384\n",
      "      BatchNorm2d-12        [-1, 256, 256, 256]             512\n",
      "           Conv2d-13        [-1, 256, 256, 256]          16,384\n",
      "      BatchNorm2d-14        [-1, 256, 256, 256]             512\n",
      "             ReLU-15        [-1, 256, 256, 256]               0\n",
      "       Bottleneck-16        [-1, 256, 256, 256]               0\n",
      "           Conv2d-17         [-1, 64, 256, 256]          16,384\n",
      "      BatchNorm2d-18         [-1, 64, 256, 256]             128\n",
      "             ReLU-19         [-1, 64, 256, 256]               0\n",
      "           Conv2d-20         [-1, 64, 256, 256]          36,864\n",
      "      BatchNorm2d-21         [-1, 64, 256, 256]             128\n",
      "             ReLU-22         [-1, 64, 256, 256]               0\n",
      "           Conv2d-23        [-1, 256, 256, 256]          16,384\n",
      "      BatchNorm2d-24        [-1, 256, 256, 256]             512\n",
      "             ReLU-25        [-1, 256, 256, 256]               0\n",
      "       Bottleneck-26        [-1, 256, 256, 256]               0\n",
      "           Conv2d-27         [-1, 64, 256, 256]          16,384\n",
      "      BatchNorm2d-28         [-1, 64, 256, 256]             128\n",
      "             ReLU-29         [-1, 64, 256, 256]               0\n",
      "           Conv2d-30         [-1, 64, 256, 256]          36,864\n",
      "      BatchNorm2d-31         [-1, 64, 256, 256]             128\n",
      "             ReLU-32         [-1, 64, 256, 256]               0\n",
      "           Conv2d-33        [-1, 256, 256, 256]          16,384\n",
      "      BatchNorm2d-34        [-1, 256, 256, 256]             512\n",
      "             ReLU-35        [-1, 256, 256, 256]               0\n",
      "       Bottleneck-36        [-1, 256, 256, 256]               0\n",
      "           Conv2d-37        [-1, 128, 256, 256]          32,768\n",
      "      BatchNorm2d-38        [-1, 128, 256, 256]             256\n",
      "             ReLU-39        [-1, 128, 256, 256]               0\n",
      "           Conv2d-40        [-1, 128, 128, 128]         147,456\n",
      "      BatchNorm2d-41        [-1, 128, 128, 128]             256\n",
      "             ReLU-42        [-1, 128, 128, 128]               0\n",
      "           Conv2d-43        [-1, 512, 128, 128]          65,536\n",
      "      BatchNorm2d-44        [-1, 512, 128, 128]           1,024\n",
      "           Conv2d-45        [-1, 512, 128, 128]         131,072\n",
      "      BatchNorm2d-46        [-1, 512, 128, 128]           1,024\n",
      "             ReLU-47        [-1, 512, 128, 128]               0\n",
      "       Bottleneck-48        [-1, 512, 128, 128]               0\n",
      "           Conv2d-49        [-1, 128, 128, 128]          65,536\n",
      "      BatchNorm2d-50        [-1, 128, 128, 128]             256\n",
      "             ReLU-51        [-1, 128, 128, 128]               0\n",
      "           Conv2d-52        [-1, 128, 128, 128]         147,456\n",
      "      BatchNorm2d-53        [-1, 128, 128, 128]             256\n",
      "             ReLU-54        [-1, 128, 128, 128]               0\n",
      "           Conv2d-55        [-1, 512, 128, 128]          65,536\n",
      "      BatchNorm2d-56        [-1, 512, 128, 128]           1,024\n",
      "             ReLU-57        [-1, 512, 128, 128]               0\n",
      "       Bottleneck-58        [-1, 512, 128, 128]               0\n",
      "           Conv2d-59        [-1, 128, 128, 128]          65,536\n",
      "      BatchNorm2d-60        [-1, 128, 128, 128]             256\n",
      "             ReLU-61        [-1, 128, 128, 128]               0\n",
      "           Conv2d-62        [-1, 128, 128, 128]         147,456\n",
      "      BatchNorm2d-63        [-1, 128, 128, 128]             256\n",
      "             ReLU-64        [-1, 128, 128, 128]               0\n",
      "           Conv2d-65        [-1, 512, 128, 128]          65,536\n",
      "      BatchNorm2d-66        [-1, 512, 128, 128]           1,024\n",
      "             ReLU-67        [-1, 512, 128, 128]               0\n",
      "       Bottleneck-68        [-1, 512, 128, 128]               0\n",
      "           Conv2d-69        [-1, 128, 128, 128]          65,536\n",
      "      BatchNorm2d-70        [-1, 128, 128, 128]             256\n",
      "             ReLU-71        [-1, 128, 128, 128]               0\n",
      "           Conv2d-72        [-1, 128, 128, 128]         147,456\n",
      "      BatchNorm2d-73        [-1, 128, 128, 128]             256\n",
      "             ReLU-74        [-1, 128, 128, 128]               0\n",
      "           Conv2d-75        [-1, 512, 128, 128]          65,536\n",
      "      BatchNorm2d-76        [-1, 512, 128, 128]           1,024\n",
      "             ReLU-77        [-1, 512, 128, 128]               0\n",
      "       Bottleneck-78        [-1, 512, 128, 128]               0\n",
      "           Conv2d-79        [-1, 256, 128, 128]         131,072\n",
      "      BatchNorm2d-80        [-1, 256, 128, 128]             512\n",
      "             ReLU-81        [-1, 256, 128, 128]               0\n",
      "           Conv2d-82          [-1, 256, 64, 64]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 64, 64]             512\n",
      "             ReLU-84          [-1, 256, 64, 64]               0\n",
      "           Conv2d-85         [-1, 1024, 64, 64]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 64, 64]           2,048\n",
      "           Conv2d-87         [-1, 1024, 64, 64]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 64, 64]           2,048\n",
      "             ReLU-89         [-1, 1024, 64, 64]               0\n",
      "       Bottleneck-90         [-1, 1024, 64, 64]               0\n",
      "           Conv2d-91          [-1, 256, 64, 64]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 64, 64]             512\n",
      "             ReLU-93          [-1, 256, 64, 64]               0\n",
      "           Conv2d-94          [-1, 256, 64, 64]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 64, 64]             512\n",
      "             ReLU-96          [-1, 256, 64, 64]               0\n",
      "           Conv2d-97         [-1, 1024, 64, 64]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 64, 64]           2,048\n",
      "             ReLU-99         [-1, 1024, 64, 64]               0\n",
      "      Bottleneck-100         [-1, 1024, 64, 64]               0\n",
      "          Conv2d-101          [-1, 256, 64, 64]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 64, 64]             512\n",
      "            ReLU-103          [-1, 256, 64, 64]               0\n",
      "          Conv2d-104          [-1, 256, 64, 64]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 64, 64]             512\n",
      "            ReLU-106          [-1, 256, 64, 64]               0\n",
      "          Conv2d-107         [-1, 1024, 64, 64]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 64, 64]           2,048\n",
      "            ReLU-109         [-1, 1024, 64, 64]               0\n",
      "      Bottleneck-110         [-1, 1024, 64, 64]               0\n",
      "          Conv2d-111          [-1, 256, 64, 64]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 64, 64]             512\n",
      "            ReLU-113          [-1, 256, 64, 64]               0\n",
      "          Conv2d-114          [-1, 256, 64, 64]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 64, 64]             512\n",
      "            ReLU-116          [-1, 256, 64, 64]               0\n",
      "          Conv2d-117         [-1, 1024, 64, 64]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 64, 64]           2,048\n",
      "            ReLU-119         [-1, 1024, 64, 64]               0\n",
      "      Bottleneck-120         [-1, 1024, 64, 64]               0\n",
      "          Conv2d-121          [-1, 256, 64, 64]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 64, 64]             512\n",
      "            ReLU-123          [-1, 256, 64, 64]               0\n",
      "          Conv2d-124          [-1, 256, 64, 64]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 64, 64]             512\n",
      "            ReLU-126          [-1, 256, 64, 64]               0\n",
      "          Conv2d-127         [-1, 1024, 64, 64]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 64, 64]           2,048\n",
      "            ReLU-129         [-1, 1024, 64, 64]               0\n",
      "      Bottleneck-130         [-1, 1024, 64, 64]               0\n",
      "          Conv2d-131          [-1, 256, 64, 64]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 64, 64]             512\n",
      "            ReLU-133          [-1, 256, 64, 64]               0\n",
      "          Conv2d-134          [-1, 256, 64, 64]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 64, 64]             512\n",
      "            ReLU-136          [-1, 256, 64, 64]               0\n",
      "          Conv2d-137         [-1, 1024, 64, 64]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 64, 64]           2,048\n",
      "            ReLU-139         [-1, 1024, 64, 64]               0\n",
      "      Bottleneck-140         [-1, 1024, 64, 64]               0\n",
      "          Conv2d-141          [-1, 512, 64, 64]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 64, 64]           1,024\n",
      "            ReLU-143          [-1, 512, 64, 64]               0\n",
      "          Conv2d-144          [-1, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-145          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-146          [-1, 512, 32, 32]               0\n",
      "          Conv2d-147         [-1, 2048, 32, 32]       1,048,576\n",
      "     BatchNorm2d-148         [-1, 2048, 32, 32]           4,096\n",
      "          Conv2d-149         [-1, 2048, 32, 32]       2,097,152\n",
      "     BatchNorm2d-150         [-1, 2048, 32, 32]           4,096\n",
      "            ReLU-151         [-1, 2048, 32, 32]               0\n",
      "      Bottleneck-152         [-1, 2048, 32, 32]               0\n",
      "          Conv2d-153          [-1, 512, 32, 32]       1,048,576\n",
      "     BatchNorm2d-154          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-155          [-1, 512, 32, 32]               0\n",
      "          Conv2d-156          [-1, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-157          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-158          [-1, 512, 32, 32]               0\n",
      "          Conv2d-159         [-1, 2048, 32, 32]       1,048,576\n",
      "     BatchNorm2d-160         [-1, 2048, 32, 32]           4,096\n",
      "            ReLU-161         [-1, 2048, 32, 32]               0\n",
      "      Bottleneck-162         [-1, 2048, 32, 32]               0\n",
      "          Conv2d-163          [-1, 512, 32, 32]       1,048,576\n",
      "     BatchNorm2d-164          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-165          [-1, 512, 32, 32]               0\n",
      "          Conv2d-166          [-1, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-167          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-168          [-1, 512, 32, 32]               0\n",
      "          Conv2d-169         [-1, 2048, 32, 32]       1,048,576\n",
      "     BatchNorm2d-170         [-1, 2048, 32, 32]           4,096\n",
      "            ReLU-171         [-1, 2048, 32, 32]               0\n",
      "      Bottleneck-172         [-1, 2048, 32, 32]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 12.00\n",
      "Forward/backward pass size (MB): 5988.02\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 6097.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5dc8a93a-1893-444a-a7de-0897c8cdb271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 512, 512]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 512, 512]             128\n",
      "              ReLU-3         [-1, 64, 512, 512]               0\n",
      "         MaxPool2d-4         [-1, 64, 256, 256]               0\n",
      "            Conv2d-5         [-1, 64, 256, 256]           4,096\n",
      "       BatchNorm2d-6         [-1, 64, 256, 256]             128\n",
      "              ReLU-7         [-1, 64, 256, 256]               0\n",
      "            Conv2d-8         [-1, 64, 256, 256]          36,864\n",
      "       BatchNorm2d-9         [-1, 64, 256, 256]             128\n",
      "             ReLU-10         [-1, 64, 256, 256]               0\n",
      "           Conv2d-11        [-1, 256, 256, 256]          16,384\n",
      "      BatchNorm2d-12        [-1, 256, 256, 256]             512\n",
      "           Conv2d-13        [-1, 256, 256, 256]          16,384\n",
      "      BatchNorm2d-14        [-1, 256, 256, 256]             512\n",
      "             ReLU-15        [-1, 256, 256, 256]               0\n",
      "       Bottleneck-16        [-1, 256, 256, 256]               0\n",
      "           Conv2d-17         [-1, 64, 256, 256]          16,384\n",
      "      BatchNorm2d-18         [-1, 64, 256, 256]             128\n",
      "             ReLU-19         [-1, 64, 256, 256]               0\n",
      "           Conv2d-20         [-1, 64, 256, 256]          36,864\n",
      "      BatchNorm2d-21         [-1, 64, 256, 256]             128\n",
      "             ReLU-22         [-1, 64, 256, 256]               0\n",
      "           Conv2d-23        [-1, 256, 256, 256]          16,384\n",
      "      BatchNorm2d-24        [-1, 256, 256, 256]             512\n",
      "             ReLU-25        [-1, 256, 256, 256]               0\n",
      "       Bottleneck-26        [-1, 256, 256, 256]               0\n",
      "           Conv2d-27         [-1, 64, 256, 256]          16,384\n",
      "      BatchNorm2d-28         [-1, 64, 256, 256]             128\n",
      "             ReLU-29         [-1, 64, 256, 256]               0\n",
      "           Conv2d-30         [-1, 64, 256, 256]          36,864\n",
      "      BatchNorm2d-31         [-1, 64, 256, 256]             128\n",
      "             ReLU-32         [-1, 64, 256, 256]               0\n",
      "           Conv2d-33        [-1, 256, 256, 256]          16,384\n",
      "      BatchNorm2d-34        [-1, 256, 256, 256]             512\n",
      "             ReLU-35        [-1, 256, 256, 256]               0\n",
      "       Bottleneck-36        [-1, 256, 256, 256]               0\n",
      "           Conv2d-37        [-1, 128, 256, 256]          32,768\n",
      "      BatchNorm2d-38        [-1, 128, 256, 256]             256\n",
      "             ReLU-39        [-1, 128, 256, 256]               0\n",
      "           Conv2d-40        [-1, 128, 128, 128]         147,456\n",
      "      BatchNorm2d-41        [-1, 128, 128, 128]             256\n",
      "             ReLU-42        [-1, 128, 128, 128]               0\n",
      "           Conv2d-43        [-1, 512, 128, 128]          65,536\n",
      "      BatchNorm2d-44        [-1, 512, 128, 128]           1,024\n",
      "           Conv2d-45        [-1, 512, 128, 128]         131,072\n",
      "      BatchNorm2d-46        [-1, 512, 128, 128]           1,024\n",
      "             ReLU-47        [-1, 512, 128, 128]               0\n",
      "       Bottleneck-48        [-1, 512, 128, 128]               0\n",
      "           Conv2d-49        [-1, 128, 128, 128]          65,536\n",
      "      BatchNorm2d-50        [-1, 128, 128, 128]             256\n",
      "             ReLU-51        [-1, 128, 128, 128]               0\n",
      "           Conv2d-52        [-1, 128, 128, 128]         147,456\n",
      "      BatchNorm2d-53        [-1, 128, 128, 128]             256\n",
      "             ReLU-54        [-1, 128, 128, 128]               0\n",
      "           Conv2d-55        [-1, 512, 128, 128]          65,536\n",
      "      BatchNorm2d-56        [-1, 512, 128, 128]           1,024\n",
      "             ReLU-57        [-1, 512, 128, 128]               0\n",
      "       Bottleneck-58        [-1, 512, 128, 128]               0\n",
      "           Conv2d-59        [-1, 128, 128, 128]          65,536\n",
      "      BatchNorm2d-60        [-1, 128, 128, 128]             256\n",
      "             ReLU-61        [-1, 128, 128, 128]               0\n",
      "           Conv2d-62        [-1, 128, 128, 128]         147,456\n",
      "      BatchNorm2d-63        [-1, 128, 128, 128]             256\n",
      "             ReLU-64        [-1, 128, 128, 128]               0\n",
      "           Conv2d-65        [-1, 512, 128, 128]          65,536\n",
      "      BatchNorm2d-66        [-1, 512, 128, 128]           1,024\n",
      "             ReLU-67        [-1, 512, 128, 128]               0\n",
      "       Bottleneck-68        [-1, 512, 128, 128]               0\n",
      "           Conv2d-69        [-1, 128, 128, 128]          65,536\n",
      "      BatchNorm2d-70        [-1, 128, 128, 128]             256\n",
      "             ReLU-71        [-1, 128, 128, 128]               0\n",
      "           Conv2d-72        [-1, 128, 128, 128]         147,456\n",
      "      BatchNorm2d-73        [-1, 128, 128, 128]             256\n",
      "             ReLU-74        [-1, 128, 128, 128]               0\n",
      "           Conv2d-75        [-1, 512, 128, 128]          65,536\n",
      "      BatchNorm2d-76        [-1, 512, 128, 128]           1,024\n",
      "             ReLU-77        [-1, 512, 128, 128]               0\n",
      "       Bottleneck-78        [-1, 512, 128, 128]               0\n",
      "           Conv2d-79        [-1, 256, 128, 128]         131,072\n",
      "      BatchNorm2d-80        [-1, 256, 128, 128]             512\n",
      "             ReLU-81        [-1, 256, 128, 128]               0\n",
      "           Conv2d-82          [-1, 256, 64, 64]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 64, 64]             512\n",
      "             ReLU-84          [-1, 256, 64, 64]               0\n",
      "           Conv2d-85         [-1, 1024, 64, 64]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 64, 64]           2,048\n",
      "           Conv2d-87         [-1, 1024, 64, 64]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 64, 64]           2,048\n",
      "             ReLU-89         [-1, 1024, 64, 64]               0\n",
      "       Bottleneck-90         [-1, 1024, 64, 64]               0\n",
      "           Conv2d-91          [-1, 256, 64, 64]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 64, 64]             512\n",
      "             ReLU-93          [-1, 256, 64, 64]               0\n",
      "           Conv2d-94          [-1, 256, 64, 64]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 64, 64]             512\n",
      "             ReLU-96          [-1, 256, 64, 64]               0\n",
      "           Conv2d-97         [-1, 1024, 64, 64]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 64, 64]           2,048\n",
      "             ReLU-99         [-1, 1024, 64, 64]               0\n",
      "      Bottleneck-100         [-1, 1024, 64, 64]               0\n",
      "          Conv2d-101          [-1, 256, 64, 64]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 64, 64]             512\n",
      "            ReLU-103          [-1, 256, 64, 64]               0\n",
      "          Conv2d-104          [-1, 256, 64, 64]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 64, 64]             512\n",
      "            ReLU-106          [-1, 256, 64, 64]               0\n",
      "          Conv2d-107         [-1, 1024, 64, 64]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 64, 64]           2,048\n",
      "            ReLU-109         [-1, 1024, 64, 64]               0\n",
      "      Bottleneck-110         [-1, 1024, 64, 64]               0\n",
      "          Conv2d-111          [-1, 256, 64, 64]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 64, 64]             512\n",
      "            ReLU-113          [-1, 256, 64, 64]               0\n",
      "          Conv2d-114          [-1, 256, 64, 64]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 64, 64]             512\n",
      "            ReLU-116          [-1, 256, 64, 64]               0\n",
      "          Conv2d-117         [-1, 1024, 64, 64]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 64, 64]           2,048\n",
      "            ReLU-119         [-1, 1024, 64, 64]               0\n",
      "      Bottleneck-120         [-1, 1024, 64, 64]               0\n",
      "          Conv2d-121          [-1, 256, 64, 64]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 64, 64]             512\n",
      "            ReLU-123          [-1, 256, 64, 64]               0\n",
      "          Conv2d-124          [-1, 256, 64, 64]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 64, 64]             512\n",
      "            ReLU-126          [-1, 256, 64, 64]               0\n",
      "          Conv2d-127         [-1, 1024, 64, 64]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 64, 64]           2,048\n",
      "            ReLU-129         [-1, 1024, 64, 64]               0\n",
      "      Bottleneck-130         [-1, 1024, 64, 64]               0\n",
      "          Conv2d-131          [-1, 256, 64, 64]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 64, 64]             512\n",
      "            ReLU-133          [-1, 256, 64, 64]               0\n",
      "          Conv2d-134          [-1, 256, 64, 64]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 64, 64]             512\n",
      "            ReLU-136          [-1, 256, 64, 64]               0\n",
      "          Conv2d-137         [-1, 1024, 64, 64]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 64, 64]           2,048\n",
      "            ReLU-139         [-1, 1024, 64, 64]               0\n",
      "      Bottleneck-140         [-1, 1024, 64, 64]               0\n",
      "          Conv2d-141          [-1, 512, 64, 64]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 64, 64]           1,024\n",
      "            ReLU-143          [-1, 512, 64, 64]               0\n",
      "          Conv2d-144          [-1, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-145          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-146          [-1, 512, 32, 32]               0\n",
      "          Conv2d-147         [-1, 2048, 32, 32]       1,048,576\n",
      "     BatchNorm2d-148         [-1, 2048, 32, 32]           4,096\n",
      "          Conv2d-149         [-1, 2048, 32, 32]       2,097,152\n",
      "     BatchNorm2d-150         [-1, 2048, 32, 32]           4,096\n",
      "            ReLU-151         [-1, 2048, 32, 32]               0\n",
      "      Bottleneck-152         [-1, 2048, 32, 32]               0\n",
      "          Conv2d-153          [-1, 512, 32, 32]       1,048,576\n",
      "     BatchNorm2d-154          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-155          [-1, 512, 32, 32]               0\n",
      "          Conv2d-156          [-1, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-157          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-158          [-1, 512, 32, 32]               0\n",
      "          Conv2d-159         [-1, 2048, 32, 32]       1,048,576\n",
      "     BatchNorm2d-160         [-1, 2048, 32, 32]           4,096\n",
      "            ReLU-161         [-1, 2048, 32, 32]               0\n",
      "      Bottleneck-162         [-1, 2048, 32, 32]               0\n",
      "          Conv2d-163          [-1, 512, 32, 32]       1,048,576\n",
      "     BatchNorm2d-164          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-165          [-1, 512, 32, 32]               0\n",
      "          Conv2d-166          [-1, 512, 32, 32]       2,359,296\n",
      "     BatchNorm2d-167          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-168          [-1, 512, 32, 32]               0\n",
      "          Conv2d-169         [-1, 2048, 32, 32]       1,048,576\n",
      "     BatchNorm2d-170         [-1, 2048, 32, 32]           4,096\n",
      "            ReLU-171         [-1, 2048, 32, 32]               0\n",
      "      Bottleneck-172         [-1, 2048, 32, 32]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                    [-1, 5]          10,245\n",
      "================================================================\n",
      "Total params: 23,518,277\n",
      "Trainable params: 23,518,277\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 12.00\n",
      "Forward/backward pass size (MB): 5988.02\n",
      "Params size (MB): 89.72\n",
      "Estimated Total Size (MB): 6089.73\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "modelOutputFeats = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(modelOutputFeats, 5)\n",
    "summary(model, (3, 1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0978a183-54a2-4a05-bd7b-e45cb9f91de0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
